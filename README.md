# HapMap
<img src="https://media.discordapp.net/attachments/780970726781222943/965747054762659840/Screen_Shot_2022-04-18_at_3.53.54_PM.png" alt="hapmap_logo" width="200"/>
HapMap is a sensory navigation application that makes independent travel more accessible for low-vision individuals. It utilizes a combination of auditory, haptic, and vibration cues to inform users of their route. For example: as the user approaches a turn, the frequency of the haptic feedback increases to indicate their proximity to the turn. This reduces the uncertainty that comes with standard navigation systems that may abruptly give instructions.

## Repo Layout
**HapMap/lib**: Files to run, edit, and integrating Google Map API to the flutter app \
-**HapMap/lib/API/** Files related to Google Maps API endpoint and returned data structures \
-**HapMap/lib/pages** Layouts and functionality for front-end UI \
-**HapMap/lib/constants.dart** global constants 
-**HapMap/lib/main.dart** Application entry point
**HapMap/reports**: Weekly reports and meeting agenda

## Related Files
[Figma Wireframe](https://www.figma.com/file/aBOhJMR48TNw95Jmrq3YMl/HapMap?node-id=0%3A1) \
[Spec and Requirements](https://docs.google.com/document/d/1I34HH7h0vPHHwxrdcsIazLe2c-b-zCE0JoaApBoYGJw/edit?usp=sharing) \
[Trello Board](https://trello.com/invite/b/SqZ7BMdB/1bc12234fd4251b4506332ddbf8a9e25/hapmap-tasks)

## Authors and Acknowledgements
This project was developed as part of the UW CSE 403: Software Engineering course by Emily Chang, Simona Liao, Jesse Hu, Lauren Cavanaugh, Pulkit Malhotra, and Aditya Nayak. Special thanks to Professor Ren√© Just and TA Hannah K. Potter for their support and guidance on this project!
